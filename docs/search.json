[
  {
    "objectID": "DP.html",
    "href": "DP.html",
    "title": "Publier un data paper",
    "section": "",
    "text": "Le data paper (DP) est une publication scientifique dont le but principal est de décrire un ensemble de données ou un groupe d’ensembles de données, pltutôt que de rendre compte d’une enquête de recherche. Vous allez vraiment décrire votre base ou jeu de données. Cela va constituer l’intégralité de votre article. Un type d’article scientifique tout aussi valable que d’autres. C’est juste une partie “matériel et méthodes” très élaborée de vos articles habituels. Le DP fait directement référence aux données : dedans il y a un lien vers les données. C’est une publication à part entière, qui fait l’objet d’un processus d’évaluation comme tout article dans une revue scientifique.\n“Publication qui décrit un jeu de données scientifiques, notamment à l’aide d’informations structurées appelées métadonnées. Contrairement aux articles de recherches classiques, les data papers fournissent une voie formalisée au partage des données plutôt que tester des hypothèses ou présenter de nouvelles analyses” (Doranum 2017)\n“Article scientifique évalué par les pairs et citable. Il décrit un jeu de données, la méthode ayant permis de l’obtenir et le potentiel de réutilisation de ce jeu” (Dedieu 2022)."
  },
  {
    "objectID": "DP.html#définition-et-enjeux-du-dp",
    "href": "DP.html#définition-et-enjeux-du-dp",
    "title": "Publier un data paper",
    "section": "",
    "text": "Le data paper (DP) est une publication scientifique dont le but principal est de décrire un ensemble de données ou un groupe d’ensembles de données, pltutôt que de rendre compte d’une enquête de recherche. Vous allez vraiment décrire votre base ou jeu de données. Cela va constituer l’intégralité de votre article. Un type d’article scientifique tout aussi valable que d’autres. C’est juste une partie “matériel et méthodes” très élaborée de vos articles habituels. Le DP fait directement référence aux données : dedans il y a un lien vers les données. C’est une publication à part entière, qui fait l’objet d’un processus d’évaluation comme tout article dans une revue scientifique.\n“Publication qui décrit un jeu de données scientifiques, notamment à l’aide d’informations structurées appelées métadonnées. Contrairement aux articles de recherches classiques, les data papers fournissent une voie formalisée au partage des données plutôt que tester des hypothèses ou présenter de nouvelles analyses” (Doranum 2017)\n“Article scientifique évalué par les pairs et citable. Il décrit un jeu de données, la méthode ayant permis de l’obtenir et le potentiel de réutilisation de ce jeu” (Dedieu 2022)."
  },
  {
    "objectID": "DP.html#les-revues-qui-publient-des-dp",
    "href": "DP.html#les-revues-qui-publient-des-dp",
    "title": "Publier un data paper",
    "section": "2. Les revues qui publient des DP",
    "text": "2. Les revues qui publient des DP\nLes DP sont reconnus tout comme des articles de recherches traditionnels, et sont indexés par Web of Knowledge (ISI), PubMedCentral, Scopus, Zoological Record, Google Scholar, CAB Abstrats, Directory of Open Access Journal (DOAJ), EBSCO.\nMême si l’offre de revue permettant de publier des data paper est limitée, plusieurs le permettent, quelques exemple : Data in Brief, Nature Scientific Data, Journal of Open Humanities Data, Research Data Journal for the Humanities and Social Sciences, F1000 Research, etc.\nMais toutes les revues ne se valent pas. Le CIRAD propose de considérer certains aspects (dedieu2022a?) :\n\nPrendre en compte l’échelle du jeu de données : est-ce un grand ou petit jeu ?\nStructure du data paper : est-ce un modèle simple dans une revue généraliste, ou disciplinaire ?\nLocalisation des données : est-ce que les données ont été déposées dans un entrepôt reconnu par la revue ? Il faut fuir les revues qui captent les données.\nModalités de diffusion des données : certaines revues imposent une licence de diffusion spécifique.\nCritères d’évaluation par les pairs : voir les instructions aux auteurs."
  },
  {
    "objectID": "DP.html#construction-dun-dp-les-spécificités",
    "href": "DP.html#construction-dun-dp-les-spécificités",
    "title": "Publier un data paper",
    "section": "3. Construction d’un DP : les spécificités",
    "text": "3. Construction d’un DP : les spécificités\nLa structure générale d’un data paper est la suivante :\n\nDescription du jeu de données et de son contexte\nDescription des méthodes d’obtention\nExplication du potentiel de réutilisation des données\n\nLes structures du data paper peuvent varier en fonction de la revue, certaines proposent des templates comme Data in Brief, Scientific Data ou Journal of Open Humanities Data."
  },
  {
    "objectID": "DP.html#quels-intérêts-dun-data-paper",
    "href": "DP.html#quels-intérêts-dun-data-paper",
    "title": "Publier un data paper",
    "section": "4. Quels intérêts d’un data paper ?",
    "text": "4. Quels intérêts d’un data paper ?\nTableau 9. Avantages collectifs et individuels à la publication d’un data paper\n\n\n\n\n\n\n\nAvantages collectifs\nAvantages individuels\n\n\n\n\nPartage sous forme de publication, avec révision avec les pairs : La publication d’un jeu de données, assortie d’une révision par les pairs, garantit et valorise la qualité des données. Cette démarche vise à assurer que les données sont fiables et ont été examinées rigoureusement par d’autres experts dans le domaine.\n\nAttribution d’un DOI : L’attribution d’un DOI (Digital Object Identifier) aux jeux de données les rend citables dans d’autres travaux de recherche. Cela augmente la visibilité des données et la probabilité d’être cité, contribuant ainsi à la reconnaissance académique du chercheur.\nValorisation du travail de constitution de la base de données : Le dépôt de données valorise le travail souvent non reconnu de constitution et de gestion de bases de données, qui représente une part significative du temps de recherche. Ce processus permet de reconnaître et de valoriser cet effort comme une contribution substantielle à la science."
  },
  {
    "objectID": "DP.html#quelques-exemples-de-templates",
    "href": "DP.html#quelques-exemples-de-templates",
    "title": "Publier un data paper",
    "section": "5. Quelques exemples de templates",
    "text": "5. Quelques exemples de templates\nLes revues spécialisées dans la publication de data papers imposent souvent des formats spécifiques et des règles détaillées pour la soumission de ces types de documents. Ces formats sont conçus pour guider les auteurs à travers un ensemble complet de questions que tout data paper devrait adresser, assurant ainsi que toutes les informations essentielles sont couvertes. Cela inclut des détails sur le fonctionnement du jeu de données, sa construction, et ses applications potentielles. En suivant ces directives, les auteurs peuvent créer des data papers qui non seulement répondent aux critères de la revue mais offrent également aux lecteurs une compréhension claire et approfondie des données présentées. Ce processus aide à garantir que les jeux de données sont non seulement accessibles mais également utilisables et pertinents pour d’autres chercheurs dans le domaine.\n\n5.1. Data in Brief\nData in Brief est une revue généraliste qui publie des articles en anglais. Pour soumettre un article, les auteurs peuvent choisir entre deux formats de template disponibles : un document Microsoft Word (.doc) ou un fichier LaTeX. Ces templates sont conçus pour guider les auteurs à travers le processus de rédaction en incluant plusieurs éléments clés :\n\nParties à remplir : Chaque section du template est destinée à être complétée avec les informations spécifiques du jeu de données.\nDes énoncés et explications : Les instructions sur ce qui est attendu dans chaque section sont généralement écrites en bleu. Cela permet de les distinguer clairement du reste du texte, aidant les auteurs à comprendre précisément ce qu’ils doivent fournir.\nDes “Commentaires” : Ces annotations supplémentaires clarifient davantage les attentes de la revue pour chaque partie du document. Elles peuvent aussi inclure des recommandations de sources ou des conseils pour aider à compléter certaines sections efficacement.\n\nCes outils sont conçus pour faciliter le processus de soumission en s’assurant que tous les aspects essentiels des données sont correctement documentés et présentés, permettant ainsi une évaluation rigoureuse et une publication efficace.\nTemplate DIB v.18 (Janvier 2024)\n\nTableau 10 - Template DIB v.18 (Janvier 2024)\n\n\n\n\n\n\n\n13 parties\nContenu\n\n\nAuthor instructions\nDonne un résumé de comment s’approprier ce template : dans sa rédaction comme après pour sa soumission.\n\n\nArticle information\n\n“Article title” : le terme “dataset” ou “database” obligatoire dans le titre.\n“Authors”\n“Affiliations”\n“Corresponding author’s email address and Twitter handle”\n“Keywords”\n“Abstract”\n\n\n\nSpecifications table\nConsiste en un tableau :\n\n“Subject” (dire le thème selon une catégorie prédéfinie de DIB)\n“Specific subject area” (en 150 caractères, sans espaces)\n“Type of data”\n“Data collection”\n“Data source location”\n“Data accessibility”\n“Related research article”\n\n\n\nValue of the data\nProposer entre 3 et 6 bullet points qui répondent à une question chacune, par exemple :\n\n“Why are these data valuable?”\n“How can these data be reused by other researchers?”\n\n\n\nBackground\nDécrire ici la motivation, la problématique, le contexte précis qui nous a poussé vers la construction de ce jeu de données.\n\n\nData description\nDécrire le jeu de données dans l’entrepôt : les noms des fichiers, les dossiers, comment se l’approprier… Aucune interprétation ou conclusion sur les données.\n\n\nExperimental design, materials and methods\nDécrire comment les données ont été produites et acquises. Description de toutes les étapes. Aucune interprétation ou conclusion sur les données.\n\n\nLimitations\nDécrire toute limites liées à ces données (à leur construction ou à ce qu’elles peuvent dire).\n\n\nEthics statement\nDIB propose des textes en fonction de la situation dans laquelle nous somme (si ce travail implique des expérimentations animales par exemple, des données collectées dans les réseaux sociaux, etc…). Ce texte correspond à la charte Elsevier.\n\n\nCredit Author Statement\nAttribuer les contributions de chaque auteur, selon la charte Elsevier.\n\n\nAcknowledgements\nMentionner ici les chercheurs qui ont contribué mais qui ne sont pas auteurs. Mentionner également les sources de financements s’il y en a. Phrase toute faite si ce travail n’est pas issu d’un financement particulier.\n\n\nDeclaration of competing interests\nChoix entre deux phrases toutes faites.\n\n\nReferences\nMaximum de 20 références. Un format précis de mise en forme est demandé : numéroter les références entre crochets. Citer également : son jeu de données, et l’article de recherche qui se base sur ces données s’il y en a un.\n\n\n\n\n\n5.2. Scientific Report (Nature)\nRevue prestigieuse de portée généraliste qui publie des articles en anglais. Pour faciliter la soumission des manuscrits, la revue met à disposition deux modèles de document, ou templates, que les auteurs peuvent utiliser selon leur préférence : l’un au format Microsoft Word (.doc) et l’autre au format LaTeX. Ces templates sont conçus pour aider les auteurs à structurer leur soumission conformément aux exigences éditoriales de la revue, assurant ainsi que tous les aspects nécessaires sont correctement adressés et présentés.\nTemplate Scientific Data (Nature) (avril 2024)\n\nTableau 11. Template de Nature Scientific Data\n\n\n\n16 parties\nContenu\n\n\nTitle\n110 caractères max, avec espaces.\n\n\nAuthors\nNoms avec institution et adresse mail.\n\n\nAbstract\nmax 170 mots.\n\n\nBackground & Summary\nContexte de la construction de ces données, les objectifs qui l’ont motivé, et leur potentiel, qu’est-ce que cela peut apporter. Recommandation : encouragent à inclure une figure qui donne un aperçu schématique de la conception de l’étude ou du flux de travail (le cas échéant).\n\n\nMethods\nDécrit toutes les étapes ou procédures utilisées pour produire ces données. Cette description doit être suffisamment détaillée pour permettre aux lecteurs de reproduire les méthodes des publications associées à partir de cette explication. Aucune limite de taille.\n\n\nData Records\nDescription détaillée d’où les données se trouvent et de comment s’approprier les données dans leur entrepôt.\n\n\nTechnical Validation\nToute expérience ou analyse nécessaire pour valider la qualité technique du jeu de données. Figures ou tableau si besoin.\n\n\nUsage Notes\nSection optionnelle. Instructions supplémentaires pour assister les chercheurs à la réutilisation de ces données.\n\n\nCode Availability\nOptionnel si on utilise un code d’usage. Indique si et comment le code peut être accessible.\n\n\nAcknowledgments\nPas de charte de référence.\n\n\nAuthor contributions\nSuivre la référence de la revue Nature (autorship policies).\n\n\nCompeting interests\nRegarder les politiques de Nature sur ce qui constitue des intérêts concurrents.\n\n\nFigures\nLes images des figures doivent être fournies sous forme de fichiers séparés et doivent être référencées à l’aide d’un système de numérotation cohérent dans l’ensemble du descripteur de données. Pour les soumissions initiales, les auteurs peuvent choisir de fournir un seul PDF avec des figures intégrées. Il vous sera ensuite demandé de fournir des fichiers séparés à l’approche de la publication. Les auteurs sont encouragés à envisager la création d’une figure décrivant le(s) processus expérimental(s) utilisé(s) pour générer et analyser les données.\n\n\nFigure Legends\nLes tableaux doivent être fournis dans un document Word dans un fichier séparé. Les tableaux peuvent être de n’importe quelle taille, mais seuls les tableaux qui tiennent sur une seule page imprimée seront inclus dans la version PDF de l’article (jusqu’à un maximum de trois). Les autres seront hébergés en tant que tableaux supplémentaires.\n\n\nTables\n\n\n\nReferences\nUtiliser les standards de Nature. Citer nos données.\n\n\n\n\n\n5.3. Journal of Open Humanities Data (JOHD)\nRevue thématique spécialisée dans les données ouvertes en sciences humaines. Cette revue a une exigence particulière concernant la longueur des soumissions : les articles ne doivent pas dépasser 1000 mots, à l’exception du titre, des affiliations des auteurs, du résumé, ainsi que des tables, figures et références qui ne sont pas inclus dans ce comptage. Le template fourni par la revue contient du texte en bleu qui sert de guide et doit être supprimé ou remplacé par le texte définitif de l’auteur, en noir. Ce système aide les auteurs à structurer leur article de manière claire et conforme aux attentes éditoriales de la revue.\nTemplate JOHD, short (avril 2024)\n\nTableau 12. Template de JOHD\n\n\n\n12 parties\nContenu\n\n\nTitle\nNoms des auteurs et affiliations.\n\n\nAuthor roles\nSelon la charte : https://credit.niso.org/\n\n\nAbstract\nRésumé d’environ 100 mots, accompagnés de mots-clés.\n\n\nOverview\n\n“Repository location” : donner le DOI du dataset\n“Context” : dans quel contexte ont été produites ces données ?\n\n\n\nMethod\nDécrire les méthodes utilisées pour créer les données, y compris les sous parties :\n\n“Steps” : les procédures, les sources, logiciels..\n“Sampling strategy” : s’il y en a, décrire la stratégie d’échantillonnage.\n“Quality control” : Si appliquable. Lister les méthodes utilisées pour le contrôle qualité.\n\n\n\nDataset Description\n\n“Repository name”\n“Object name”\n“Format names and versions”\n“Creation dates”\n“Dataset creators”\n“Language”\n“License”\n“Publication date” du dataset dans l’entrepôt\n\n\n\nReuse Potentiel\nDécrire les façons dont les données peuvent être réutilisées par d’autres chercheurs.\n\n\nAcknowledgments\nPas de charte précise.\n\n\nFunding statement\nPas de charte précise.\n\n\nCompeting interests\nSi aucun intérêt écrire “The author(s) has/have no competing interests to declare”.\n\n\nReferences\nAPA style et inclure DOI si valables.\n\n\nSupplementary Files\nTous les fichiers supplémentaires/complémentaires qui doivent être liés à la publication principale doivent être listés, avec un numéro correspondant, un titre et une description de l’option. Les fichiers supplémentaires doivent également être cités dans le texte principal."
  },
  {
    "objectID": "DP.html#la-question-du-coût-dun-data-paper",
    "href": "DP.html#la-question-du-coût-dun-data-paper",
    "title": "Publier un data paper",
    "section": "6. La question du coût d’un data paper",
    "text": "6. La question du coût d’un data paper\n\n6.1. Le principe de l’auteur-payeur : coûts élevés\nLes publications de data paper reposent sur le modèle de l’ “auteur-payeur”, principe selon lequel les auteurs ou leurs institutions financent les frais de publication afin de rendre leurs travaux librement accessibles au public. Ce modèle est souvent associé aux revues dites en “Gold Open Access” (voies dorées).\nPlusieurs contraintes accompagnent ce modèle :\n\nCoûts élevés de publication : Les frais de publication, connus sous le nom d’Article Processing Charges (APC), peuvent être prohibitifs, allant de quelques centaines à plusieurs milliers d’euros par article. Cette barrière financière peut limiter la capacité des chercheurs, surtout ceux provenant d’institutions avec des ressources limitées ou des pays à faible revenu, à publier leurs travaux.\nInégal accès à la publication : L’accès inégal aux ressources financières peut désavantager certains chercheurs, affectant ainsi la visibilité et l’impact de leurs recherches en fonction de leur capacité à supporter ces coûts.\nImpact sur la qualité de la recherche : Une vigilance accrue est nécessaire concernant les revues ‘prédatrices’, qui peuvent favoriser les bénéfices financiers au détriment de la rigueur scientifique.\nAlternatives limitées : Bien que des alternatives comme la publication dans des revues sans APC (voie diamant) existent, elles sont moins nombreuses et peuvent offrir une visibilité moindre pour les travaux publiés.\n\n\n\n6.2. Quelques solutions existantes\nDes solutions diverses voient le jour :\n\nDans le contexte français, le consortium Couperin est une association d’établissements de l’Enseignement Supérieur et de la Recherche français visant à développer l’accès à l’information scientifique et technique pour la communauté scientifique. Il facilite les négociations nationales de ressources documentaires numériques, notamment avec les grands groupes d’éditions américains, et soutient la science ouverte. Le consortium évalue, négocie et organise l’achat de ressources documentaires numériques au bénéfice de ses membres. Le consortium négocie des accords avec les éditeurs pour réduire les frais de publication en Open Access pour ses membres, qui incluent des universités, grandes écoles, et autres institutions de recherche françaises. Ces accords visent à obtenir des conditions tarifaires avantageuses et parfois même des dispenses complètes sur les APC (Article Processing Charges). Ces négociations permettent de soutenir la science ouverte en réduisant la barrière financière pour les chercheurs.\nAccords avec des éditeurs (‘open access agreements’) : certains éditeurs ont des arrangements spécifiques avec des pays ou des institutions pour réduire les APC. Ces accords peuvent varier considéablement d’un pays à l’autre et d’un éditeur à l’autre, souvent négociés à l’échelle institutionnelle ou nationale. Par exemple, divers éditeurs ont mis en place des accords transformants qui visent à transitionner du modèle d’abonnement traditionnel à un modèle de libre accès, souvent en réduisant ou en couvrant les APC pour les institutions participantes.\nTableau 13. Open Access Agreements par revue\n\n\n\nData in Brief (Politique d’Elsevier 1 ; 2) : 850$ brut\nNature Scientific Data (Politique de Springer 1 ; 2) : 2290$ brut\nJournal Of Humanities Data (Politique Ubiquity Press) : 730$ [1]\n\n\n\n\n\nEurope : Consortiums nationaux majeurs en Autriche, Bulgarie, Danemark, Finlande, France, Allemagne, Grèce, Hongrie, Italie, Malte, Pays-Bas, Norvège, Pologne, Portugal, Roumanie, Slovaquie, Slovénie, Espagne, Suède, et Suisse (incluant CERN et Swiss Universities).\nAmérique du Nord : Nombreux établissements et consortiums aux États-Unis, incluant California State University, Carnegie Mellon University, et University of California ; Canada représenté par le Canadian Research Knowledge Network (CRKN)\nOcéanie : Australie ; Nouvelle-Zélande\nAsie : Japon.; Corée du Sud ; Taiwan ; Inde ; Indonésie ; Qatar ; Arabie Saoudite ; Singapour ; Thaïlande\nAmérique latine : Colombie et Brésil\nAfrique : Afrique du Sud avec le SANLiC Consortium\n\n\nPays classés “à faibles revenus” selon la Banque Mondiale sont dispensés d’APC : concerne en majorité des pays d’Afrique (Madagascar, Burundi, Burkina Faso…) à l’exception de l’Ukraine depuis l’invasion de la Russie.\nPays à “faible-moyen revenus” avec un PIB en dessous des 200$ bénéficient d’une réduction d’APC de 50% : concerne notamment la Côte d’Ivoire, le Sénégal, ou encore le Maroc.\nLes autres sont évalués au cas par cas.\n\n\nUn des prix les plus bas pour les revues.\nPas d’aide ou de dispense d’APC dans ce contexte."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Outils fondamentaux de la science ouverte : PGD, entrepôt de données et data paper",
    "section": "",
    "text": "version avril 2024\nCe manuel est le fruit des journées Science Ouverte de l’UMI SOURCE d’avril 2024 à Abidjan (Côte d’Ivoire). Il offre une introduction à outils essentiels de la science ouverte :\nConçu pour être évolutif et collaboratif, ce texte s’enrichira progressivement grâce aux contributions des partenaires des antennes de l’UMI SOURCE en Côte d’Ivoire, France, Madagascar et Sénégal. Ainsi, ce manuel vise à être une ressource vivante, qui grandit et s’adapte aux besoins de la communauté scientifique engagée dans la pratique de la science ouverte."
  },
  {
    "objectID": "index.html#quest-ce-que-la-science-ouverte",
    "href": "index.html#quest-ce-que-la-science-ouverte",
    "title": "Outils fondamentaux de la science ouverte : PGD, entrepôt de données et data paper",
    "section": "Qu’est-ce que la “science ouverte” ?",
    "text": "Qu’est-ce que la “science ouverte” ?\nLa science ouverte marque un changement profond dans la culture de la recherche, influençant à la fois notre façon de créer de la connaissance (transformation épistémologique) et l’utilisation de nouvelles technologies. Elle met en avant la transparence et la collaboration entre chercheurs. Adopter cette approche offre plusieurs avantages : elle permet de reproduire plus facilement les résultats obtenus par d’autres, stimulant ainsi la confiance et l’efficacité scientifiques. De plus, elle encourage l’innovation et la créativité, ouvrant la voie à de nouvelles découvertes et avancées.\nQuelques définitions issues de la littérature :\n\n“Open Science is transparent and accessible knowledge that is shared and developed through collaborative networks” (Vicente-Saez and Martinez-Fuentes 2018).\n“an inclusive construct that combines various movements and practices aiming to make multilingual scientific knowledge openly available, accessible and reusable for everyone, to increase scientific collaborations and sharing of information for the benefits of science and society, and to open the processes of scientific knowledge creation, evaluation and communication to societal actors beyond the traditional scientific community” (UNESCO 2021).\n“collaborature culture enabled by technology that empowers the open sharing of data, information, and knowledge within the scientific community and the wider public to accelerate scientific research and understanding” (Ramachandran, Bugbee, and Murphy 2021)."
  },
  {
    "objectID": "data_info.html",
    "href": "data_info.html",
    "title": "Éléments introductifs sur les données",
    "section": "",
    "text": "Selon l’OECD (2007) : “enregistrements factuels (chiffres, textes, images et sons), qui sont utilisés comme sources principales pour la recherche scientifique et sont généralement reconnus par la communauté scientifique comme nécessaires pour valider des résultats de recherche”.\nSelon Rivet et al. (2018) : “les données de la recherche concernent à la fois des échantillons, les données administratives et les données scientifiques tant manuscrites (cahiers de laboratoire…) que numériques”.\nSelon l’ARDC (2023) : “means data in the form of facts, observations, images, computer program results, recordings, measurements or experiences on which an argument, theory, test or hypothesis, or other research output is based. It relates to data generated, collected, or used during research projects, and in some cases may include the research output itself. Data may be numerical, descriptive, visual or tactile. It may be raw, cleaned or processed, and may be held in any format or media. Research data, in many disciplines, may by necessity include the software, algorithm, model and/or parameters, used to arrive at the research outcome, in addition to the raw data that the software, algorithm or model is applied to”.\n\nVoici quelques exemples de types de données utilisés en science ouverte [Données de la Recherche - 1. Introduction | ENPC]. :\n\nDonnées d’observation : Les données d’observation sont recueillies en observant des phénomènes ou des comportements sans les influencer. Elles sont souvent collectées dans des environnements naturels ou en situation réelle, sans intervention directe du chercheur. Ces données peuvent inclure des observations de phénomènes ou de comportements, ou par exemple de relevés environnementaux (température, les précipitations, ou des images de télédétection), .\nDonnées expérimentales : Il s’agit des résultats obtenus lors d’expériences en laboratoire, comme les mesures de réactions chimiques ou l’observation de comportements biologiques. Ce type de données est généralement collecté dans un cadre contrôlé, où le chercheur peut manipuler les variables et mesurer les résultats.\nDonnées d’enquêtes : Les données d’enquête sont recueillies en interrogeant des personnes ou des groupes de personnes sur leurs opinions, leurs attitudes ou leurs comportements. Ces données sont généralement collectées via des questionnaires, des interviews ou des sondages. Elles permettent de comprendre les attitudes, opinions ou comportements des participants.\nDonnées qualitatives : Elles comprennent des descriptions narratives, des transcriptions d’entretiens, des notes de terrain, ou des analyses de contenu. Ces données aident à explorer les aspects plus nuancés et détaillés d’un sujet d’étude.\nDonnées quantitatives : Ces données sont numériques qui peuvent être mesurées et analysées statistiquement. Elles permettent de quantifier des phénomènes ou des comportements et de faire des comparaisons entre différents groupes ou conditions.\nCes données peuvent être classées “primaires” ou “secondaires” :\nDonnées primaires (ou brutes) : enregistrements factuels (chiffres, textes, images et sons), sources principales pour la recherche scientifique, reconnus comme nécessaires pour valider des résultats de recherche (OECD 2007). Informations collectées directement par le chercheur pour la première fois, spécifiquement dans le but de répondre à une question de recherche. Ces données n’ont pas été modifiées ou traitées depuis leur collecte. Elles sont originales.\nDonnées secondaires, dérivées : informations qui ont déjà été collectées et enregistrées par une personne autre que l’utilisateur dans un but qui ne concerne pas le problème de sa recherche actuelle. Elles impliquent des informations de seconde main, elles peuvent être quantitatives ou qualitatives et sont généralement disponibles sous une forme raffinée. Elles peuvent inclure des analyses, des résumés ou des traitements supplémentaires des données primaires pour soutenir de nouvelles recherches ou conclusions.\nDonnées d’intérêt : réutilisables afin d’améliorer les connaissances par l’enrichissement, la combinaison à d’autres jeux de données. Ce sont des données qui se réfèrent à des informations pertinentes ou bénéfiques pour un domaine d’étude particulier.\n\n\n\n\nTableau - Différences entre Dataset et Database (Dedieu and Fily Marie-Françoise 2015)\n\n\n\n\n\n\n\n\n\nJeu de données (Dataset)\nBase de données (Database)\n\n\n\n\nDéfinition\nCollection d’informations organisées de manière structurée, souvent sous forme de tableaux. Ce regroupement est conçu pour faciliter l’analyse des données. Un jeu de données peut représenter une portion d’une base de données plus vaste, ou bien constituer une unité complète de données dédiée à un sujet spécifique ou à une analyse particulière.\nCollection structurée de jeux de données. Elle est conçue pour stocker, organiser, et gérer de grandes quantités d’informations de manière efficace. Grâce à des systèmes de gestion de bases de données, elle permet l’accès facile aux données, ainsi que leur modification et gestion. Une base de données peut contenir plusieurs jeux de données différents et est généralement utilisée pour le stockage de données à long terme et pour des opérations complexes de traitement de données.\n\n\n\n\n\n\nLe “cycle de vie” des données est souvent représenté comme suit (OECD 2007) :\n\nConnaître et comprendre le “cycle de vie des données” est essentiel pour plusieurs raisons :\n\nPlanification de la recherche : Une bonne compréhension du cycle de vie des données aide à organiser efficacement les différentes phases de gestion des données, depuis la préparation et la collecte jusqu’à leur utilisation et conservation, assurant ainsi une base solide pour le projet de recherche (UPSaclay 2023).\nAccès et préservation : En suivant les étapes du cycle de vie, on s’assure que les données restent accessibles et utilisables par d’autres chercheurs, ce qui renforce la transparence et la possibilité de reproduire les résultats. Cela contribue également à la préservation sécurisée et pérenne des données. (Université Grenoble Alpes 2024).\nValorisation des données : Il aide à maximiser la valorisation des données en favorisant leur réutilisation dans d’autres contextes de recherche, ce qui peut conduire à de nouvelles découvertes ou innovations (Batifol et al. 2021).\nRespect des normes et des principes éthiques : Une bonne compréhension du cycle de vie des données permet de respecter les normes réglementaires et éthiques, y compris les principes FAIR (facilement trouvables, accessibles, interopérables, réutilisables), essentiels pour la gestion des données de recherche\nMinimisation des impacts environnementaux : En anticipant les étapes du cycle de vie, on peut planifier des stratégies pour minimiser les impacts environnementaux liés à l’acquisition, au traitement et à la diffusion des données (“Impacts environnementaux de la gestion et de l’ouverture des données”, Université Paris-Saclay)."
  },
  {
    "objectID": "data_info.html#les-données-de-la-recherche-définitions-typologies-usages",
    "href": "data_info.html#les-données-de-la-recherche-définitions-typologies-usages",
    "title": "Éléments introductifs sur les données",
    "section": "",
    "text": "Selon l’OECD (2007) : “enregistrements factuels (chiffres, textes, images et sons), qui sont utilisés comme sources principales pour la recherche scientifique et sont généralement reconnus par la communauté scientifique comme nécessaires pour valider des résultats de recherche”.\nSelon Rivet et al. (2018) : “les données de la recherche concernent à la fois des échantillons, les données administratives et les données scientifiques tant manuscrites (cahiers de laboratoire…) que numériques”.\nSelon l’ARDC (2023) : “means data in the form of facts, observations, images, computer program results, recordings, measurements or experiences on which an argument, theory, test or hypothesis, or other research output is based. It relates to data generated, collected, or used during research projects, and in some cases may include the research output itself. Data may be numerical, descriptive, visual or tactile. It may be raw, cleaned or processed, and may be held in any format or media. Research data, in many disciplines, may by necessity include the software, algorithm, model and/or parameters, used to arrive at the research outcome, in addition to the raw data that the software, algorithm or model is applied to”.\n\nVoici quelques exemples de types de données utilisés en science ouverte [Données de la Recherche - 1. Introduction | ENPC]. :\n\nDonnées d’observation : Les données d’observation sont recueillies en observant des phénomènes ou des comportements sans les influencer. Elles sont souvent collectées dans des environnements naturels ou en situation réelle, sans intervention directe du chercheur. Ces données peuvent inclure des observations de phénomènes ou de comportements, ou par exemple de relevés environnementaux (température, les précipitations, ou des images de télédétection), .\nDonnées expérimentales : Il s’agit des résultats obtenus lors d’expériences en laboratoire, comme les mesures de réactions chimiques ou l’observation de comportements biologiques. Ce type de données est généralement collecté dans un cadre contrôlé, où le chercheur peut manipuler les variables et mesurer les résultats.\nDonnées d’enquêtes : Les données d’enquête sont recueillies en interrogeant des personnes ou des groupes de personnes sur leurs opinions, leurs attitudes ou leurs comportements. Ces données sont généralement collectées via des questionnaires, des interviews ou des sondages. Elles permettent de comprendre les attitudes, opinions ou comportements des participants.\nDonnées qualitatives : Elles comprennent des descriptions narratives, des transcriptions d’entretiens, des notes de terrain, ou des analyses de contenu. Ces données aident à explorer les aspects plus nuancés et détaillés d’un sujet d’étude.\nDonnées quantitatives : Ces données sont numériques qui peuvent être mesurées et analysées statistiquement. Elles permettent de quantifier des phénomènes ou des comportements et de faire des comparaisons entre différents groupes ou conditions.\nCes données peuvent être classées “primaires” ou “secondaires” :\nDonnées primaires (ou brutes) : enregistrements factuels (chiffres, textes, images et sons), sources principales pour la recherche scientifique, reconnus comme nécessaires pour valider des résultats de recherche (OECD 2007). Informations collectées directement par le chercheur pour la première fois, spécifiquement dans le but de répondre à une question de recherche. Ces données n’ont pas été modifiées ou traitées depuis leur collecte. Elles sont originales.\nDonnées secondaires, dérivées : informations qui ont déjà été collectées et enregistrées par une personne autre que l’utilisateur dans un but qui ne concerne pas le problème de sa recherche actuelle. Elles impliquent des informations de seconde main, elles peuvent être quantitatives ou qualitatives et sont généralement disponibles sous une forme raffinée. Elles peuvent inclure des analyses, des résumés ou des traitements supplémentaires des données primaires pour soutenir de nouvelles recherches ou conclusions.\nDonnées d’intérêt : réutilisables afin d’améliorer les connaissances par l’enrichissement, la combinaison à d’autres jeux de données. Ce sont des données qui se réfèrent à des informations pertinentes ou bénéfiques pour un domaine d’étude particulier.\n\n\n\n\nTableau - Différences entre Dataset et Database (Dedieu and Fily Marie-Françoise 2015)\n\n\n\n\n\n\n\n\n\nJeu de données (Dataset)\nBase de données (Database)\n\n\n\n\nDéfinition\nCollection d’informations organisées de manière structurée, souvent sous forme de tableaux. Ce regroupement est conçu pour faciliter l’analyse des données. Un jeu de données peut représenter une portion d’une base de données plus vaste, ou bien constituer une unité complète de données dédiée à un sujet spécifique ou à une analyse particulière.\nCollection structurée de jeux de données. Elle est conçue pour stocker, organiser, et gérer de grandes quantités d’informations de manière efficace. Grâce à des systèmes de gestion de bases de données, elle permet l’accès facile aux données, ainsi que leur modification et gestion. Une base de données peut contenir plusieurs jeux de données différents et est généralement utilisée pour le stockage de données à long terme et pour des opérations complexes de traitement de données.\n\n\n\n\n\n\nLe “cycle de vie” des données est souvent représenté comme suit (OECD 2007) :\n\nConnaître et comprendre le “cycle de vie des données” est essentiel pour plusieurs raisons :\n\nPlanification de la recherche : Une bonne compréhension du cycle de vie des données aide à organiser efficacement les différentes phases de gestion des données, depuis la préparation et la collecte jusqu’à leur utilisation et conservation, assurant ainsi une base solide pour le projet de recherche (UPSaclay 2023).\nAccès et préservation : En suivant les étapes du cycle de vie, on s’assure que les données restent accessibles et utilisables par d’autres chercheurs, ce qui renforce la transparence et la possibilité de reproduire les résultats. Cela contribue également à la préservation sécurisée et pérenne des données. (Université Grenoble Alpes 2024).\nValorisation des données : Il aide à maximiser la valorisation des données en favorisant leur réutilisation dans d’autres contextes de recherche, ce qui peut conduire à de nouvelles découvertes ou innovations (Batifol et al. 2021).\nRespect des normes et des principes éthiques : Une bonne compréhension du cycle de vie des données permet de respecter les normes réglementaires et éthiques, y compris les principes FAIR (facilement trouvables, accessibles, interopérables, réutilisables), essentiels pour la gestion des données de recherche\nMinimisation des impacts environnementaux : En anticipant les étapes du cycle de vie, on peut planifier des stratégies pour minimiser les impacts environnementaux liés à l’acquisition, au traitement et à la diffusion des données (“Impacts environnementaux de la gestion et de l’ouverture des données”, Université Paris-Saclay)."
  },
  {
    "objectID": "data_info.html#traiter-analyser-et-fairiser-ses-données",
    "href": "data_info.html#traiter-analyser-et-fairiser-ses-données",
    "title": "Éléments introductifs sur les données",
    "section": "2. Traiter, Analyser et FAIRiser ses données",
    "text": "2. Traiter, Analyser et FAIRiser ses données\n\n2.1. Les 4 principes fondamentaux de la Science Ouverte : les principes FAIR\nLes principes FAIR sont des lignes directrices conçues pour améliorer la gestion et l’utilisation des données numériques par les communautés de recherche. Ils représentent des bonnes pratiques de la science ouverte (SO) et encouragent l’adoption d’une culture spécifique à adopter sur les données. Ces principes visent à garantir que les données soient préparées et conservées de manière à faciliter leur partage et leur utilité, non seulement pour la communauté scientifique, mais aussi pour d’autres secteurs. Leur philosophie peut se résumer par la maxime : “aussi ouvert que possible, mais aussi fermé que nécessaire” (EUR-Lex 2019).\nCes principes ont été formalisés pour la première fois en janvier 2014 lors de l’initiative Data FAIRport, marquant un tournant dans l’importance de ces standards pour la gestion des données de recherche (Data FAIRport). En 2016, un article fondateur publié dans Nature Scientific Data expose les principes du FAIR, soulignant leur rôle crucial dans la promotion de l’accès et de la réutilisation des données de recherche (Wilkinson et al. 2016).\n\n\n\nLettres\nEn anglais\nEn français\nExplication\n\n\nF\nFindable\nFacile à trouver\nLes données doivent être faciles à trouver tant pour les humains que pour les machines. Cela implique l’utilisation de métadonnées détaillées et bien organisées, qui décrivent les données de manière précise, et leur enregistrement dans des registres de recherche reconnus. Ces pratiques assurent que les données peuvent être rapidement localisées et utilisées correctement par ceux qui en ont besoin, facilitant ainsi la recherche et l’analyse (CCSD CNRS).\n\n\nA\nAccessible\nAccessible\nAprès avoir localisé les données, il est crucial qu’elles soient accessibles via des protocoles transparents et ouverts. Ces protocoles doivent assurer que l’accès aux données reste possible, même quand celles-ci ne sont plus actibement gérées. Cela signifie que les données doivent être stockées de manière à ce que, indépendamment de leur maintenance active, elles restent disponibles pour consultation ou utilisation future (Université de Genève).\n\n\nI\nInteroperable\nInteropérable\nLes données doivent être stockées dans des formats qui facilitent leur intégration avec d’autres ensembles de données. Ce choix de formats assure l’interopérabilité, permettant ainsi aux différents systèmes informatiques de travailler ensemble de manière efficace. En pratique, cela signifie que les données peuvent être combinées ou comparées avec d’autres données de manière simple, ce qui est crucial pour les analyses complexes et multidisciplinaires (Institut Pasteur).\n\n\nR\nRe-usable\nRéutilisable\nLes données doivent être documentées de manière exhaustive afin de faciliter leur réutilisation dans de futurs projets de recherche. Cela inclut non seulement une description détaillée des données elles-mêmes, mais aussi des informations claires sur les conditions d’utilisation et les licences associées. Une documentation complète permet à d’autres chercheurs de comprendre rapidement comment les données ont été collectées et comment elles peuvent être légalement utilisées, assurant ainsi une transition fluide et éthique vers de nouvelles recherches.\n\n\n\nCes bonnes pratiques concernent principalement :\n\nLes formats : Un format peut soit être “propriétaire”, soit “libre” (ou “ouvert”, “pérenne”). En SO, il est recommandé d’utiliser des formats de données libres, pour la documentation et le partage des données. Ces formats sont privilégiés car ils ne dépendent pas de logiciels spécifiques qui pourraient devenir obsolètes, ce qui assure leur accessibilité et leur utilité à long terme. Bien que les formats propriétaires ne soient pas interdits, ils ne s’alignent pas pleinement sur les principes FAIR, car ils peuvent limiter l’accès et la réutilisation des données. Si un format libre n’est pas disponible, le dépôt des données dans un format propriétaire est toujours possible, mais l’accessibilité sera plus restreinte. Utiliser des formats libres favorise l’interopérabilité et la réutilisation des données, conformément aux principes FAIR, et nécessite une réévaluation régulière des solutions de sauvegarde et de stockage pour s’assrer que les données restent accessibles et surveillées.\n\nTableau 1. “Liste indicative de formats ouverts et fermés” (fiche syntétique sur doranum.fr - 2017)\n\n\n\n\n\n\n\n\nType de fichier\nFormat ouvert\nFormat fermé\n\n\n\n\nTraitement de texte\nABW (Abiword)\nDOCX (Document Office Open XML)\nODT (OpenDocument Text)\nRTF (Rich Text Format)\nTXT (Text)\nDOC (Microsoft Word)\nPAGES\nWP (WordPerfect)\n\n\nImage\nBMP (Windows BitMaP)\nGIF (Graphics Interchange Format)\nJPG (Joint Photographic Expert Group)\nPNG (Portable Network Graphics)\nJP2 (Joint Photographic Expert Group 2000)\nTIF (Tagged Image File Format)\n\n\nTableur\nXLSX (Tableur Office Open XML)\nCSV (Comma-separated values)\nODS (OpenDocument SpreadSheet)\nTSV (Tab Seperated Values)\nXLS (Microsoft Excel)\nNUMBERS\n\n\nRetouche d’image\nORA (OpenRaster)\nXCF (eXperimental Computing Facility)\nCPT (Corel Photo-Paint)\nPFI (PhotoFiltre)\nPSD (PhotoShop Document)\n\n\nVidéo\nMKV (Matroska)\nNUT\nOGM (OGG Media)\nAVI (Audio Video Interleave)\nFLV (Flash Video)\nMOV (QuickTime Movie)\nMP4 (MPEG-4 Part 14)\nQT (QuickTime Movie)\nRM (Real Media)\nWMV (Windows Media Video)\n\n\nAudio\nFLAC\nMPC (Musepack)\nOGG\nOPUS (Opus Interactive Audio Codec)\nWAV (Windows Media Audio)\nAAC (Advanced Audio Coding)\nMP3 (MPEG-1/2_Audio_Laye_III)\nRAM (Real Audio Metadata)\nWMA (Windows Media Audio)\n\n\nPrésentation\nODP (OpenDocument Presentation)\nPPTX (Presentation Office Open XML)\nKEY (Keynote)\nPPT (Microsoft PowerPoint)\n\n\nArchivage - Compression\n7z (Seven Zip)\nTAR (Tape ARchiver)\nZIP\nACE\nRAR (Roshal ARchive)\n\n\nDessin vectoriel\nEPS (Encapsulated PostScript)\nODG (OpenDocument Graphics)\nSVG (Scalable Vector Graphics)\nAI (Adobe Illustrator Artwork)\nCDR (CoreIDRAW)\nFH (Adobe FreeHand)\n\n\nLangage de description de pages\nXPS (XML Paper Specification)\nPS (PostScript)\nPDF (Portable Document Format)\nCSS (Cascading Style Sheets)\nHTML (HyperText Markup Language)\nXHTML (Extensible Hypertext Markup Language)\n\n\n\n\n\nLes identifiants : c’est un code unique associé à une personne ou à un objet. Un identifiant unique est essentiel pour le fonctionnement du “web sémantique”, qui permet de référencer et de connecter une personne ou un objet à travers l’ensemble du réseau internet. Il existe deux types d’identifiants principaux :\n\nL’identifiant objet : utilisé pour les productions scientifiques telles que les publications et les données de recherche ;\nL’identifiant contributeur : destiné aux auteurs et aux institutions.\n\nUn identifiant efficace doit être pérenne, c’est-à-dire qu’il reste valide et reconnaissable sur le long terme grâce à des mécanismes informatiques dédiés. Par exemple, pour éviter la confusion due aux homonymes sur Google Scholar par exemple, un identifiant unique et pérenne permet d’identifier précisément une personne. Ainsi, l’identifiant joue un rôle clé dans le principe FAIR “Findable” (facilement trouvable), assurant que les informations sont facilement localisables et distinguables sur internet.\n\n\nLe Web Sémantique\n\nLe Web sémantique utilise des métadonnées et des langages spécifiques développés par le World Wide Web Consortium (W3C) pour enrichir le contenu web. Ces métadonnées permettent de décrire explicitement la sémantique ou le sens des informations, facilitant ainsi leur recherche, leur interconnexion et leur réutilisation par des applications informatiques. Ainsi, il relie les données entre elles, crée des réseaux, de manière à ce qu’elles puissent être facilement interconnectées et consultées à travers différentes sources. Ces connexions sont effectuées à l’aide de métadonnées qui décrivent le contenu et la relation entre les données. Il encourage l’utilisation de formats de données et de protocoles d’échange standardisés, comme le Resource Description Framework (RDF), pour assurer la cohérence et l’interopérabilité des données sur le Web (optimize360.fr ; ionos.fr).\n\nDe l’importance d’un identifiant ORCID pour un chercheur (identifiant contributeur)\n\nORCID est un code international, unique, gratuit et pérenne attribué à chaque chercheur pour améliorer la gestion des informations personnelles et professionnelles. Ce système soutient la transparence et la collaboration en science ouverte, et renforce la fiabilité de l’attribution des travaux académiques ( Deboin (2015) ; (universitédangers2024?)). Voici quelques-uns des principaux avantages d’ORCID :\n\nIdentification unique : ORCID attribue à chaque chercheur un identifiant numérique qui le distingue des autres, réduisant ainsi les confusions causes par des homonymes ou des variations dans l’enregistrement des noms.\nFacilitation de la collaboration : ORCID offre un moyen simple pour les chercheurs de s’identifier et de se connecter avec d’autres spécialistes dans leur domaine, favorisant ainsi les échanges et les collaborations scientifiques.\nGestion des données de recherche : En science ouverte, où le partage des données est crucial, ORCID aide à organiser et à attribuer correctement les données de recherche aux bons auteurs. Cela simplifie la gestion des droits et la reconnaissance des contributions.\nIntégration avec les systèmes d’information académiques : ORCID s’intègre avec de nombreux systèmes d’information académiques, permettant une synchronisation des informations de recherche à travers diverses plateformes et bases de données, ce qui rend la gestion des informations académiques plus efficace et moins sujette à erreur (orcid-france.fr).\n\n\nLe DOI, Digital Object Identifier (Identifiant objet)\n\nLe DOI (Digital Object Identifier) est un identifiant numérique permanent utilisé principalement pour les documents publiés, tels que les articles de recherche, les chapitres de livres, les données et d’autres types de contenus académiques (ouvrirlascience.fr). En SO, le DOI joue un rôle crucial en facilitant l’accès, la réutilisation des recherches, leur traçabilité et leur intégrité sur le long terme. Voici quelques-uns des principaux avantages du DOI :\n\nIdentification standardisée et permanente : Le DOI fournit une méthode uniforme pour identifier de manière durable les objets électroniques publiés, assurant ainsi que chaque ressource numérique, comme les articles de recherche et les données, peut être localisée de manière fiable et durable.\nFacilitation du référencement et de la citation : Les DOI facilitent le référencement et la citation des travaux académiques en fournissant un lien stable qui mène directement à l’objet numérique, ce qui est crucial pour l’attribution correcte et la reconnaissance académique.\nStabilité des liens : Contrairement aux URL, qui peuvent changer ou devenir obsolètes, les DOI restent constants. Cela résout le problème de l’obsolescence des liens et assure un accès continu aux ressources numériques.\nIntégration avec les systèmes de gestion académique : Le système de DOI est intégré à de nombreux systèmes de gestion de l’information académique, permettant une interconnectivité et une facilité de gestion des références et des métadonnées associées à chaque ressource.\n\n\n\n\nLes métadonnées : ce sont des descriptions structurées qui cataloguent et organisent les données. Elles jouent un rôle crucial dans le web sémantique, facilitant le référencement des travaux de recherche à travers des mots, des expressions ou des phrases types qui sont eux-mêmes indexés. Au lieu de rester isolées, les données enrichies de métadonnées s’intègrent dans un réseau d’éléments similaires ou interconnectés, ce qui est vital pour leur récupération et leur visibilité dans les recherches. Une bonne structuration des métadonnées améliore le référencement et la visibilité des travaux de recherche. Pour ce faire, il existe plusieurs systèmes de métadonnées standardisés parmi lesquels choisir avant de publier une production scientifique, comme Dublin Core, DataCite Metadata Schema ou Data Documentation Initiative (DDI). Les métadonnées sont essentielles pour adhérer à plusieurs principes de gestion des données, notamment être ‘Trouvable’ (Findable), ‘Réutilisable’ (Reusable), et ‘Interopérable’ (Interoperable). Choisir le bon schéma de métadonnées permet de s’assurer que les données ne sont pas seulement accessibles mais aussi intégrables avec d’autres recherches et utilisables dans de nouveaux contextes scientifiques.\n\n\n\n2.2. Acteurs des données\nDe nombreux acteurs jouent un rôle essentiel dans le domaine des données de recherche. Les chercheurs génèrent et utilisent ces données pour mener leurs études, tandis que les financeurs, tels que les agences gouvernementales ou les organisations privées, soutiennent financièrement la recherche et veillent à la bonne gestion des résultats obtenus. Les législateurs sont également impliqués, établissant les normes et régulations qui encadrent la gestion, la protection et le partage des données. De leur côté, les organismes de recherche coordonnent la production scientifique et facilitent la gestion des données. Enfin, les services d’appui à la recherche offrent une assistance nécessaire pour le stockage, l’archivage et l’accessibilité des données, garantissant ainsi leur bonne gestion tout au long de leur cycle de vie.\n\nHorizon Europe\n\nHorizon Europe est le programme-cadre de l’Union européenne pour la recherche et l’innovation, couvrant la période de 2021 à 2027. Ce programme succède à Horizon 2020 et met un accent particulier sur la science ouverte pour stimuler l’innovation scientifique et technologique à travers l’Europe. Il met en place des financements, politiques et des pratiques qui facilitent non seulement l’accès aux publications scientifiques mais aussi le partage ouvert des données de recherche (science-ouverte.inrae.fr).\n\nUNESCO\n\nEn 2021, l’UNESCO a adopté une série de recommandations sur la science ouverte, visant à promouvoir une approche plus inclusive et collaborative de la science. Ces recommandations représentent un effort significatif pour aligner les pratiques scientifiques mondiales avec les principes de transparence, d’accessibilité et de collaboration, et ont été largement soutenues par les États membres de l’UNESCO (UNESCO 2021).\n\nLa Plateforme Africaine de Science Ouverte (AOSP)\n\nHébergée par la Fondation nationale de la recherche (NRF) d’Afrique du Sud depuis 2020, l’AOSP vise à positionner les scientifiques et les systèmes scientifiques en Afrique à la pointe de la science ouverte à forte intensité de données. Elle s’engage dans des activités telles que l’évaluation de la capacité et de l’activité de la science ouverte, l’élaboration de cadres directeurs sur les politiques, les infrastructures et le renforcement des capacités.\n\nL’exemple de la Côte d’Ivoire\n\nEn Côte d’Ivoire, plusieurs initiatives montrent un engagement croissant vers la science ouverte, avec des politiques et des actions visant à promouvoir l’accès et le partage des connaissances scientifiques :\n\nSymposium national sur la science ouverte 2022 : Organisé par le ministère de l’Enseignement supérieur et de la recherche scientifique (MERS) en collaboration avec l’Université virtuelle de Côte d’Ivoire (UVCI), ce symposium visait à élaborer une feuille de route consensuelle pour la science ouverte en Côte d’Ivoire. Il s’inscrit dans le cadre de la Recommandation de l’Unesco de 2021 (cio-mag.com).\nPolitique de Science Ouverte à l’Université Virtuelle de Côte d’Ivoire (UVCI) : L’UVCI a adopté une politique de science ouverte, abordant des notions, enjeux, et problématiques liées à l’ouverture des données de recherche. Cette politique vise à intégrer pleinement la science ouverte dans les activités académiques et de recherche (ird.fr).\nCollaboration régionale et internationale : La Côte d’Ivoire participe également à des initiatives régionales telles que WACREN (le réseau de recherche et d’éducation de l’Afrique de l’Ouest et du Centre), qui promeut la science ouverte à travers des conférences et des collaborations (oacps-ri.eu).\n\n\n\nDes ressources existent pour maîtriser, s’entraîner ou se préparer : Doranum, OPIDor, Omeka, Huma-Num… Ces plateformes jouent un rôle clé dans la promotion des pratiques de science ouverte en France, en fournissant les ressources et outils nécessaires pour une meilleure gestion des données scientifiques.\n\nDoranum\n\nDoRANum (Données de la Recherche: Apprentissage NUMérique) est une plateforme dédiée à la formation et à la sensibilisation autour de la gestion et du partage des données de recherche. Elle offre des ressources éducatives pour aider les chercheurs à comprendre et mettre en pratique les principes de la gestion des données de recherche, y compris la rédaction de plans de gestion de données (PGD) (doranum.fr).\n\nOPIDor\n\nOPIDoR (Outil de Pilotage Intégré pour les Données et les Outils de la Recherche) est un service qui propose des outils pour faciliter la gestion des données de recherche. Cela inclut des aides à la rédaction et à la mise en œuvre de plans de gestion de données. OPIDoR est particulièrement connu pour son outil de rédaction DMP (Data Management Plan), qui guide les chercheurs à travers le processus de planification de la gestion de leurs données, logiciels ou autres produits de recherche (dmp.opidor.fr).\n\n\n\n\n2.3. Archiver : pérenniser ses données\nIl est important de distinguer les termes stockage, sauvegarde et archivage, qui diffèrent principalement par la durée de préservation des données.\nLe stockage se réfère à la conservation des données à court terme, généralement pour quelques mois ou années, et sert principalement à un accès rapide et régulier.\nLa sauvegarde, quant à elle, est envisagée pour une durée intermédiaire, souvent inférieure à 15 ans, et vise à protéger les données contre les pertes éventuelles.\nL’archivage est destiné à la conservation des données sur le long terme, pour une période dépassant les 15 ans, et est utilisé pour les informations dont on ne nécessite pas un accès fréquent mais qui doivent être préservées pour des raisons légales, historiques, ou de recherche future.\nA titre indicatif, un résumé des ordres de grandeur des données :\nTableau 2. “Ordres de grandeur des données” (Rivet et al. 2018)\n\nEnfin, il est important de stocker/sauvegarde ses données sur différentes sources pour plus de sécurité. Un principe courant en Science Ouverte est la règle “3-2-1” : 3 copies, 2 supports, dont 1 déporté (bu.univ-lille.fr).\n\nTrois copies des données : Il est recommandé de conserver trois copies distinctes de toutes les données importantes pour prévenir la perte due à des défaillances matérielles, des erreurs humaines, ou des catastrophes naturelles\nDeux supports différents : Les trois copies devraient être stockées sur au moins deux types de supports différents pour minimiser le risque de défaillance simultanée. Les supports peuvent inclure des disques durs, des serveurs en réseau, des SSDs, des supports optiques, etc.\nUne copie hors site : Au moins une des copies devrait être conservée hors site pour se protéger contre les risques liés à un emplacement physique, tels que les incendies, les inondations, ou les vols. Cette copie peut être stockée dans un emplacement géographiquement distinct ou sur un cloud sécurisé\n\nTableau 3. “Comparatif des différents supports de stockage” (Fiche Doranum)"
  },
  {
    "objectID": "data_info.html#la-juridiction-des-données-ouvrir-et-clore-les-données",
    "href": "data_info.html#la-juridiction-des-données-ouvrir-et-clore-les-données",
    "title": "Éléments introductifs sur les données",
    "section": "3. La juridiction des données : ouvrir et clore les données",
    "text": "3. La juridiction des données : ouvrir et clore les données\nPlusieurs situations où le cadre juridique autour des données apparaît :\n\nPour des données anonymes : si les données utilisées pour la recherche sont des données anonymes (non identifiantes et ceci de manière irréversible), la réglementation sur la protection des données personnelles ne s’applique pas. Ne pas confondre “anonymisation” et pseudonymisation”.\n\nAnonymisation\n\nIrréversible, ne permet plus la réidentification d’une personne : “nécessite que l’identification des personnes devienne impossible, que ce soit de manière directe ou indirecte” (André-Poyaud et al. 2019).\n\nPseudonymisation\n\n“Données à caractère personnel qui ne peuvent plus directement être attribuées à la personne concernée. Mais le recours à des informations supplémentaires, par exemple une table de correspondance, permet de réidentifier cette dernière. Dans ce cas la réglementation sur la protection des données personnelles s’applique. […] Consistent à séparer les données directement identifiantes (exemple: nom et prénom) des autres données non identifiantes (exemple, en attribuant un numéro aux personnes évitant de faire apparaître leur nom, mais en conservant une table de correspondance permettant de remonter à l’identité de la personne)” (André-Poyaud et al. 2019).\n\n\nPour des données dites “sensibles” : par exemple qui “révèlent la prétendue origine raciale ou ethnique, les opinions politiques, les convictions philosophiques ou religieuses, l’appartenance syndicale, l’orientation sexuelle, les données de santé, les données biométriques qui permettent d’identifier une personne, les données génétiques” (André-Poyaud et al. 2019).\nLa question, cruciale, des licences.\n\n\nLes licences en science ouverte (SO)\n\nElles jouent un rôle crucial en définissant les modalités de partage et d’utilisation des données et publications scientifiques. Un aperçu des principaux types de licences souvent utilisées dans le contexte de la science ouverte :\n\nLes Licences Creative Commons (CC) : cf graphique ci-dessous. Concerne les articles de recherche, revues, livres, données de recherche, méthodologies ou matériaux pédagogiques.\nLes Licences pour logiciels : (1) GNU General Public License (GPL) ; MIT License ; Apache License (scienceouverte.univ-grenoble-alpes.fr).\nLes Licences pour bases de données : Open Database License (ODbL), permet aux utilisateurs de partager, modifier et utiliser la base de données tout en maintenant cette même liberté pour les autres (scienceouverte.univ-grenoble-alpes.fr).\n\n\n\nGraphique - Résumé sur les licences Creatives Commons (CC) (fabriquerel.org)"
  },
  {
    "objectID": "PGD.html",
    "href": "PGD.html",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "",
    "text": "Le terme “Plan de Gestion des Données” (PGD) est issu de l’anglicisme “Data Management Plan” (DMP). Le PGD est un document structuré et évolutif qui décrit l’ensemble des données produites ou utilisées dans le cadre d’un projet ou d’une structure. Ce plan sert à inventorier les questions essentielles concernant l’acquisition, la gestion, la conservation, ou le partage des données de recherche.\nRédiger le PGD revient à élaborer une sorte de check-list qui aide à structurer le document et à s’assurer que tous les aspects importants de la gestion des données sont couverts. Ce processus guide la manière de gérer chaque type de données. Étant donné que le PGD est évolutif, il peut être révisé et adapté à plusieurs reprises tout au long du projet. Par exemple, le programme Horizon Europe recommande la rédaction de trois versions du PGD : une dans les six premiers moi,s une autre durant le projet, et une versino finale à son achèvement.\nLe PGD accompagne le cycle de vie des données en prenant en compte toutes ses étapes, depuis la création et la collecte jusqu’) la préservation, le partage, l’accès, et la réutilisation des données. Il aborde des questions crucialestelles que les mesures pour garantir la confidentialité des données. En somme, le PGD permet aux chercheurs et à leurs collaborateurs de se réunir pour planifier efficacement la gestion des données dès le début du projet, assurant ainsi leur protection, leur sécurité et leur valorisation optimale. C’est un outil stratégique essentiel pour toute équipe de recherche."
  },
  {
    "objectID": "PGD.html#le-pgd-quest-ce-que-cest",
    "href": "PGD.html#le-pgd-quest-ce-que-cest",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "",
    "text": "Le terme “Plan de Gestion des Données” (PGD) est issu de l’anglicisme “Data Management Plan” (DMP). Le PGD est un document structuré et évolutif qui décrit l’ensemble des données produites ou utilisées dans le cadre d’un projet ou d’une structure. Ce plan sert à inventorier les questions essentielles concernant l’acquisition, la gestion, la conservation, ou le partage des données de recherche.\nRédiger le PGD revient à élaborer une sorte de check-list qui aide à structurer le document et à s’assurer que tous les aspects importants de la gestion des données sont couverts. Ce processus guide la manière de gérer chaque type de données. Étant donné que le PGD est évolutif, il peut être révisé et adapté à plusieurs reprises tout au long du projet. Par exemple, le programme Horizon Europe recommande la rédaction de trois versions du PGD : une dans les six premiers moi,s une autre durant le projet, et une versino finale à son achèvement.\nLe PGD accompagne le cycle de vie des données en prenant en compte toutes ses étapes, depuis la création et la collecte jusqu’) la préservation, le partage, l’accès, et la réutilisation des données. Il aborde des questions crucialestelles que les mesures pour garantir la confidentialité des données. En somme, le PGD permet aux chercheurs et à leurs collaborateurs de se réunir pour planifier efficacement la gestion des données dès le début du projet, assurant ainsi leur protection, leur sécurité et leur valorisation optimale. C’est un outil stratégique essentiel pour toute équipe de recherche."
  },
  {
    "objectID": "PGD.html#quel-format-adopter",
    "href": "PGD.html#quel-format-adopter",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "2. Quel format adopter ?",
    "text": "2. Quel format adopter ?\nBien qu’il existe différents modèles (’templates’) de PGD, le contenu de base reste largement similaire d’un modèle à l’autre. Ces modèles varient principalement dans les questions spécifiques posées, mais ils couvrent tous une série d’éléments fondamentaux qui apparaissent systématiquement. Ces éléments principaux incluent généralement des questions sur la collecte des données, leur stockage, gestion, partgae, préservation, et les mesures de sécurité et de confidentialité à appliquer. Ainsi, malgré les variations dans les questions ou la structure des différents modèles, l’objectif central reste le même : assurer une gestion efficace et sécurisée des données tout au long de leur cycle de vie, conformément aux exigences du projet et des normes de recherche en vigueur. Ces mêmes éléments principaux apparaissent systématiquement (fiche synthétique Doranum) :\n\nLa plateforme DMP Opidor offre un support en ligne pour la rédaction des Plans de Gestion des Données (PGD). L’Institut de Recherche pour le Développement (IRD) recommande d’utiliser le modèle fourni par l’Agence Nationale de la Recherche (ANR), jugé adapté à toutes les disciplines. L’interface DMP Opidor est conçue pour guider les chercheurs à travers le processus de rédaction du PGD en posant des questions pertinentes qui couvrent les différents aspects de la gestion des données, facilitant ainsi une approche structurée et complète adaptée à un large éventail de domaines de recherche.\nTableau 3. Éléments principaux d’un PGD\n\n\n\n\n\n\n\n\nÉléments\nCommentaires\nTypes de questions\n\n\n\n\nDescription des données\nLors de la rédaction d’un PGD, il est crucial de décrire précisément quelles données seront collectées ou produites au cours du projet. Cela inclut une identification détaillée des types de données (numériques, textuelles, audiovisuelles, etc.), des formats dans lesquels elles seront sauvegardées (PDF, Excel, JPEG, etc.) ou du volume de données attendu (en téraoctets, gigaoctets, etc.). Il est également important de spécifier comment ces données seront obtenues, en distinguant entre les données préexistantes qui seront utilisées et les nouvelles données qui seront générées spécifiquement pour le projet. Cette étape permet de s’assurer que toutes les données pertinentes sont prises en compte et gérées de manière adéquate tout au long du projet.\nIl conviendra de décrire :\n\nLe type de données : Précisez la nature des données, comme numériques, textuelles, images, audio, vidéos, etc., ainsi que les logiciels qui seront utilisés pour les créer ou les traiter.\nLes formats des données : Indiquez les formats dans lesquels les données seront sauvegardées, en privilégiant les formats ouverts (tels que .txt, .csv, pdf, .gif, etc.) pour faciliter l’accessibilité et la réutilisation.\nLa provenance des données : Décrivez d’où proviendront les données, que ce soit par la collecte de nouvelles données, la conversion ou transformation de données existantes, le partage ou l’échange avec d’autres chercheurs, ou encore l’achat.\nMéthodes et outils employés : Détaillez les méthodes et les outils qui seront utilisés pour collecter, traiter, et analyser les données, en soulignant toute technologie ou technique spécifique nécessaire pour le projet.\n\n\n\nDocumentation et qualité\nIl est important de spécifier plusieurs aspects techniques pour assurer une bonne organisation et gestion des données :\n\nMétadonnées et standards : Identifiez les métadonnées qui seront utilisées pour décrire les données collectées, y compris les standards de métadonnées à adopter. Les métadonnées facilitent la recherche, l’accès et la réutilisation des données, et doivent être choisies selon les normes reconnues dans votre domaine.\nStructuration des dossiers et nommage des fichiers : Décrivez la manière dont les dossiers seront organisés et les fichiers nommés. Il convient de mettre en place des conventions de nommage claires qui incluent des informations pertinentes telles que la date, le type de données, et d’autres identifiants utiles. Cela aide à retrouver facilement les données et à comprendre leur contenu sans avoir à les ouvrir.\nGestion des versions : Établissez des procédures pour la gestion des versions des fichiers pour éviter la confusion entre les différentes mises à jour ou modifications des données. Cela inclut la documentation des changements et la conservation des versions précédentes pour référence ultérieure.\nContrôle qualité : Précisez les méthodes de contrôle qualité qui seront utilisées pour s’assurer de l’intégrité et de l’exactitude des données. Cela peut inclure des procédures de vérification des données, des méthodes d’analyse et la définition des unités de mesure.\n\nVoici les aspects à clarifier :\n\nProduction des métadonnées : Expliquez le processus par lequel les métadonnées seront générées. Il est important de spécifier qui sera responsable de leur création, les informations qu’elles incluront, et comment elles seront maintenues à jour tout au long du projet.\nStandards de métadonnées : Identifiez les standards ou schémas de métadonnées qui seront utilisés, tels que Datacite, Dublin Core, ou d’autres pertinents à votre discipline. L’utilisation de standards reconnus garantit que les métadonnées sont cohérentes, interopérables et réutilisables par d’autres chercheurs ou plateformes.\nProcédure de contrôle qualité des données : Détaillez les méthodes de contrôle qualité qui seront mises en place pour s’assurer de la précision et de la fiabilité des données collectées. Cela peut inclure la vérification de la saisie des données, la validation des données par des revues croisées, et d’autres mécanismes de contrôle pour minimiser les erreurs et garantir la qualité des données.\n\n\n\nSauvegarde et stockage des données au cours du projet\nComment les données seront-elles stockées et sauvegardées tout au long du processus de recherche ? Il s’agit ici d’expliquer quel processus de stockage des données sera mis en place durant le projet, afin d’en garantir l’accès pour l’ensemble des collaborateurs du projet.\n\nQuels seront les supports de stockage (sereur sécurisé de votre institution, espace de travail collaboratif, etc.) ?\nQuel système de nommage sera utilisé ? La fiabilité d’accès aux données pour l’ensemble d’une équipe passe par un système de nommage unique et précis des fichiers.\nQuelle sera la volumétrie des données ? Une estimation suffit\nComment sera organisée la sauvegarde des données ?\nComment sont gérées les versions ?\n\n\n\nExigences légales et éthiques\nIl est crucial d’aborder les implications éthiques et juridiques associées à la collecte, l’utilisation et le partage des données. Voici les questions importantes à considérer :\n\nNature des données : Déterminez si les données collectées ou utilisées sont de nature sensible. Cela peut inclure des informations personnelles, des données de santé, des détails financiers, etc., qui nécessitent des précautions particulières en termes de gestion et de protection.\nQuestions éthiques et juridiques : Identifiez les enjeux éthiques et les obligations légales spécifiques liés à vos données. Cela peut concerner la confidentialité, le consentement des participants, les droits à la protection des données personnelles, et les règles de partage des données.\nAnonymisation des données : Expliquez comment sera assurée l’anonymisation ou la pseudonymisation des données sensibles pour protéger l’identité des participants. Précisez les techniques qui seront utilisées pour retirer ou masquer les identifiants personnels, garantissant ainsi que les données ne puissent pas être reliées à une personne spécifique sans accès à des informations supplémentaires.\n\n\nQui sera titulaire des droits de propriété intellectuelle sur les données (qui aura le droit d’en contrôler l’accès) ?\nEst-ce qu’un accord de consortium a été rédigé, si le projet se déroule dans le cadre d’un partenariat ?\nEst-ce que des données protégées par des droits spécifiques seront utilisées au cours du projet : par exemple, des données personnelles, des bases de données etc…\nQuelles mesures seront prises pour garantir la confidentialité des données personnelles ? Pour des données personnelles par exemple, vous pouvez envisager la pseudonymsation ou l’anonymisation, vous pouvez aussi envisager le chiffrement des données.\nIl faut mentionner l’existence d’éventuels comités d’éthique pour votre institution ou unité.\n\n\n\nStratégie de partage et d’ouverture des données\nLe PGD doit montrer qu’une réflexion est menée à propos de l’ouverture et du partage de vos données, tout en gardant le principe « aussi ouvert que possible, aussi fermé que nécessaire » au cœur de la démarche.\nPossibilité de préciser :\n\nS’il y a une obligation de partage\nS’il y a une restriction ou interdiction de partage, par exemple pour des raisons éthiques, si les données seront confidentielles ou personnelles, soumises à une propriété intellectuelle, commerciale, ou pour des raisons de sécurité.\nAvec qui les données seront partagées (accès ouvert ou restreint) ? Sachant que même si vos données seront libre accès, vous pouvez décider quand même d’un embargo sur ces données avant de les rendre publiques.\nDans quel entrepôt les données seront-elles déposées ?\nQuelles licences seront appliquées ?\nUn identifiant pérenne (ex:DOI) sera-t-il attribué ?\n\n\n\nPréservation à long terme des données\nVous aurez à aborder aussi l’aspect « préservation à long terme : quel archivage à long terme pour quelles données ? Dans quelles conditions ?\n\nQuelles sont les données sélectionnées pour l’archivage\nQuelle volumétrie prévue pour ces données ?\nQuelle durée de conservation à long terme ?\nQuel budget prévu pour l’archivage ?"
  },
  {
    "objectID": "PGD.html#qui-rédige-le-pgd",
    "href": "PGD.html#qui-rédige-le-pgd",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "3. Qui rédige le PGD ?",
    "text": "3. Qui rédige le PGD ?\nGénéralement, c’est le porteur du projet ou le principal chercheur qui rédige la première version du Plan de Gestion des Données (PGD), mais l’élaboration de ce document peut bénéficier de l’apport de plusieurs autres acteurs. Ces derniers peuvent inclure des co-chercheurs, des gestionnaires de données, des bibliothécaires spécialisés en sciences de l’information, et des conseillers juridiques, tous contribuant à différents aspects du PGD.\nDe plus, pour aider l’auteur dans la rédaction d’un PGD, diverses ressources en ligne et feuilles de route sont disponibles. Ces outils offrent des conseils, des modèles, et des recommandations spécifiques pour aborder les différentes sections du PGD, assurant que toutes les exigences légales, éthiques, et de gestion sont couvertes. Ces ressources sont conçues pour faciliter le processus d’écriture du PGD, le rendant plus accessible et moins intimidant pour les chercheurs.\nTableau 4. Ressources pour accompagner la rédaction d’un PGD [Doucouré & Hensens “Préalable et socle d’une bonne gestion des données scientifiques” 2023]\n\n\n\nExemples de PGD\nQuelques sites de référence\nRespecter les standards de sa communauté\nServices d’appuis\n\n\n\nDMP OPIDoR\nDMP primés\nDCC\nDMPTool\n\n\nIRD Data\nCoopist CIRAD\nDatapartage INRAE\nDoranum\nDCC\n\n\nRecommandations UNESCO (2021)\nLe site Science Europe établit des recommandations\nModèles des financeurs lors d’une réponse à appel d’offre.\n\n\nBibliothécaires\nIngénieurs\nRéférents données de votre laboratoire"
  },
  {
    "objectID": "PGD.html#quel-intérêts-du-pgd",
    "href": "PGD.html#quel-intérêts-du-pgd",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "4. Quel intérêts du PGD ?",
    "text": "4. Quel intérêts du PGD ?\nTableau 5. Avantages collectifs et individuels liés à l’élaboration d’un PGD\n\n\n\n\n\n\n\nAvantages collectifs\nAvantages individuels\n\n\n\n\n\nGage de bonne gestion des données : Le PGD est reconnu par les bailleurs de fonds et les pairs comme un indicateur de bonne gestion des données, contribuant ainsi à la traçabilité et à la reproductibilité des données, et améliorant leur qualité globale.\nEn suivant les principes FAIR :\n\nAssure la reproductibilité des expériences en décrivant clairement les données.\nFacilite la réutilisation en garantissant la compréhension des données.\nPermet un stockage sûr pour éviter les pertes de données.\nClarifie le cadre juridique et éhtique, respectant ainsi les droits et la dignité des personnes.\nSpécifie les modalités de partage de données, clarifiant les droits de réutilisation.\nDéfinit les responsabilités concernant la gestion des données pendant le projet.\n\n\n\nSupport pour la gestion des données : Le PGD sert de guide pour la gestion des données, offrant une structure et une vue globale sur l’ensemble des données manipulées dans le projet.\nDéveloppement professionnel : Pour un jeune chercheur notamment, maîtriser la rédaction et l’application d’un PGD est une compétence valorisée qui peut améliorer les perspectives de carrière, notamment pour l’obtention de contrats ou de postes futurs."
  },
  {
    "objectID": "PGD.html#le-pgd-outil-contraignant",
    "href": "PGD.html#le-pgd-outil-contraignant",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "5. Le PGD outil contraignant ?",
    "text": "5. Le PGD outil contraignant ?\nEffectivement, l’élaboration d’un PGD peut initialement sembler être une contrainte supplémentaire, surtout en considérant les diverses exigences déjà présentes dans les demandes de financement et la rédaction de projets de recherche. Cependant, il est important de noter que bien que la première rédaction d’un PGD puisse prendre un peu de temps, surtout en raison de la familiarisation avec le processus, ce coût initial d’entrée est souvent rapidement compensé.\nUne fois que les chercheurs acquièrent de l’expérience avec leur premier PGD, les rédactions suivantes deviennent beaucoup plus rapides et moins laborieuses. Si vous travaillez régulièrement avec le même type de données et les mêmes organismes, de nombreux aspects du PGD peuvent être réutilisés ou légèrement adaptés, ce qui réduit considérablement le temps et l’effort nécessaires pour les versions ultérieures. Ainsi, le PGD devient non seulement une partie intégrante de la gestion efficace des données, mais aussi un outil plus maniable et moins intimidant au fil du temps."
  },
  {
    "objectID": "PGD.html#quelques-références",
    "href": "PGD.html#quelques-références",
    "title": "Élaborer un Plan de Gestion des Données (PGD)",
    "section": "6. Quelques références",
    "text": "6. Quelques références\n\nRecommandations de l’ANR pour le PGD.\nOpidor : \n\n\nDMP Opidor : après créatino d’un compte vous pouvez créer vos plans de PGD.\nCat OPIDoR \nLivret “Outils et services pour accompagner a gestion des données de la recherche”\n\n\nGuide pratique pour une harmonisation internationale de la gestion des données de recherche\nDoranum aspects juridiques\nLe site Ouvrir la science\nVidéos “La journée Science Ouverte de l’IRD” à l’Université Virtuelle de Côte d’Ivoivre, Abidjan :\n\nhttps://www.youtube.com/watch?v=F6qE4Zl1y4k&t=10926s\nhttps://www.youtube.com/watch?v=SA4I-vxUKeM&t=8621s"
  },
  {
    "objectID": "repository.html",
    "href": "repository.html",
    "title": "Déposer ses données",
    "section": "",
    "text": "Lorsque vous avez produit un jeu de données, vous avez la possibilité de le valoriser en tant que ressource autonome. Le temps et l’effort investis dans la création de ces données peuvent être reconnus à travers le système de citations ou de reconnaissance par les pairs, surtout si vous déposez ces données dans un entrepôt reconnu. Cela permet non seulement de partager des données numériques mais aussi, potentiellement, de les lier à des publications associées.\nLe dépôt de données présente des avantages non seulement pour le chercheur ou l’équipe de projet, mais aussi pour la communauté scientifique dans son ensemble, en améliorant la connaissance du patrimoine de données existant, toutes disciplines confondues. Cela aide également à éviter la duplication inutile des efforts de recherche, car il informe clairement qui travaille sur quoi et qui possède quelles données.\nLes fonctions principales d’un entrepôt de données incluent le dépôt, la description, la conservation, le référencement, la diffusion, et la recherche de jeux de données. Une grande diversité de données peut être déposée, qu’elles soient liées à un article, un projet de recherche, ou qu’elles concernent des domaines spécifiques comme la géographie, l’économie, ou le climat. Par exemple, après une enquête, il est possible de déposer un tableur résumant les variables et résultats d’intérêt ainsi que les questionnaires utilisés pour obtenir ces résultats. L’objectif du dépôt est de permettre aux autres chercheurs de s’approprier et de reproduire les données de manière autonome, grâce à une documentation complète qui explique comment les données ont été produites.\nTableau 6. Avantages collectifs et individuels liés au dépôt d’un jeu de données\n\n\n\n\n\n\n\nAvantages collectifs\nAvantages individuels\n\n\n\n\n\nPartager avec la communauté scientifique : Le dépôt des données permet de les rendre accessibles à l’ensemble de la communauté scientifique, favorisant ainsi la collaboration et l’enrichissement mutuel des connaissances.\nRenforcer la visibilité d’un projet de recherche : En déposant les données, le projet gagne en visibilité, ce qui peut attirer l’attention de potentiels collaborateurs et augmenter l’impact global de la recherche.\n\n\nPréservation des données : Le dépôt permet de sécuriser les données, évitant ainsi leur perte éventuelle et garantissant leur conservation à long terme, notamment avant un départ ou une transition.\nConfiance et crédibilité : La disponibilité des données vise à soutenir la confiance dans les résultats scientifiques, en permettant la reproductibilité et en renforçant la transparence de la recherche.\nCitation et reconnaissance : En obtenant un DOI pour les jeux de données, le chercheur assure que ces derniers peuvent être cités de manière précise dans d’autres travaux de recherche, ce qui contribue à leur reconnaissance académique et à celle de leur auteur.\n\n\n\n\nLes données déposées doivent également répondre aux principes FAIR (Facile à trouver, Accessible, Interopérable, Réutilisable) :\nTableau 7. FAIRiser les données déposées (Wilkinson et al. 2016). Traduis de l’anglais au français par nous-même.\n\n\n\n\n\n\nLes principes FAIR appliqués au dépôt des données\n\n\n\n\nPour être trouvable :\nF1. Les (méta)données se voient attribuer un identifiant unique et persistant à l’échelle mondiale\nF2. Les données sont décrites avec des métadonnées riches (définies par R1 ci-dessous)\nF3. Les métadonnées incluent clairement et explicitement l’identifiant des données qu’elles décrivent\nF4. Les (méta)données sont enregistrées ou indexées dans une ressource consultable\nPour être accessible :\nA1. Les (méta)données sont récupérables par leur identifiant en utilisant un protocole de communication standardisé\nA1.1 Le protocole est ouvert, gratuit et universellement implémentable\nA1.2 Le protocole permet une procédure d’authentification et d’autorisation, lorsque nécessaire\nA2. Les métadonnées restent accessibles, même lorsque les données ne sont plus disponibles\nPour être interopérable :\nI1. Les (méta)données utilisent un langage formel, accessible, partagé et largement applicable pour la représentation du savoir.\nI2. Les (méta)données utilisent des vocabulaires qui respectent les principes FAIR\nI3. Les (méta)données incluent des références qualifiées à d’autres (méta)données\nPour être réutilisable :\nR1. Les (méta)données sont richement décrites avec une pluralité d’attributs précis et pertinents\nR1.1. Les (méta)données sont publiées avec une licence d’utilisation des données claire et accessible\nR1.2. Les (méta)données sont associées à une provenance détaillée\nR1.3. Les (méta)données répondent aux normes communautaires pertinentes au domaine"
  },
  {
    "objectID": "repository.html#quest-ce-que-déposer-ses-données",
    "href": "repository.html#quest-ce-que-déposer-ses-données",
    "title": "Déposer ses données",
    "section": "",
    "text": "Lorsque vous avez produit un jeu de données, vous avez la possibilité de le valoriser en tant que ressource autonome. Le temps et l’effort investis dans la création de ces données peuvent être reconnus à travers le système de citations ou de reconnaissance par les pairs, surtout si vous déposez ces données dans un entrepôt reconnu. Cela permet non seulement de partager des données numériques mais aussi, potentiellement, de les lier à des publications associées.\nLe dépôt de données présente des avantages non seulement pour le chercheur ou l’équipe de projet, mais aussi pour la communauté scientifique dans son ensemble, en améliorant la connaissance du patrimoine de données existant, toutes disciplines confondues. Cela aide également à éviter la duplication inutile des efforts de recherche, car il informe clairement qui travaille sur quoi et qui possède quelles données.\nLes fonctions principales d’un entrepôt de données incluent le dépôt, la description, la conservation, le référencement, la diffusion, et la recherche de jeux de données. Une grande diversité de données peut être déposée, qu’elles soient liées à un article, un projet de recherche, ou qu’elles concernent des domaines spécifiques comme la géographie, l’économie, ou le climat. Par exemple, après une enquête, il est possible de déposer un tableur résumant les variables et résultats d’intérêt ainsi que les questionnaires utilisés pour obtenir ces résultats. L’objectif du dépôt est de permettre aux autres chercheurs de s’approprier et de reproduire les données de manière autonome, grâce à une documentation complète qui explique comment les données ont été produites.\nTableau 6. Avantages collectifs et individuels liés au dépôt d’un jeu de données\n\n\n\n\n\n\n\nAvantages collectifs\nAvantages individuels\n\n\n\n\n\nPartager avec la communauté scientifique : Le dépôt des données permet de les rendre accessibles à l’ensemble de la communauté scientifique, favorisant ainsi la collaboration et l’enrichissement mutuel des connaissances.\nRenforcer la visibilité d’un projet de recherche : En déposant les données, le projet gagne en visibilité, ce qui peut attirer l’attention de potentiels collaborateurs et augmenter l’impact global de la recherche.\n\n\nPréservation des données : Le dépôt permet de sécuriser les données, évitant ainsi leur perte éventuelle et garantissant leur conservation à long terme, notamment avant un départ ou une transition.\nConfiance et crédibilité : La disponibilité des données vise à soutenir la confiance dans les résultats scientifiques, en permettant la reproductibilité et en renforçant la transparence de la recherche.\nCitation et reconnaissance : En obtenant un DOI pour les jeux de données, le chercheur assure que ces derniers peuvent être cités de manière précise dans d’autres travaux de recherche, ce qui contribue à leur reconnaissance académique et à celle de leur auteur.\n\n\n\n\nLes données déposées doivent également répondre aux principes FAIR (Facile à trouver, Accessible, Interopérable, Réutilisable) :\nTableau 7. FAIRiser les données déposées (Wilkinson et al. 2016). Traduis de l’anglais au français par nous-même.\n\n\n\n\n\n\nLes principes FAIR appliqués au dépôt des données\n\n\n\n\nPour être trouvable :\nF1. Les (méta)données se voient attribuer un identifiant unique et persistant à l’échelle mondiale\nF2. Les données sont décrites avec des métadonnées riches (définies par R1 ci-dessous)\nF3. Les métadonnées incluent clairement et explicitement l’identifiant des données qu’elles décrivent\nF4. Les (méta)données sont enregistrées ou indexées dans une ressource consultable\nPour être accessible :\nA1. Les (méta)données sont récupérables par leur identifiant en utilisant un protocole de communication standardisé\nA1.1 Le protocole est ouvert, gratuit et universellement implémentable\nA1.2 Le protocole permet une procédure d’authentification et d’autorisation, lorsque nécessaire\nA2. Les métadonnées restent accessibles, même lorsque les données ne sont plus disponibles\nPour être interopérable :\nI1. Les (méta)données utilisent un langage formel, accessible, partagé et largement applicable pour la représentation du savoir.\nI2. Les (méta)données utilisent des vocabulaires qui respectent les principes FAIR\nI3. Les (méta)données incluent des références qualifiées à d’autres (méta)données\nPour être réutilisable :\nR1. Les (méta)données sont richement décrites avec une pluralité d’attributs précis et pertinents\nR1.1. Les (méta)données sont publiées avec une licence d’utilisation des données claire et accessible\nR1.2. Les (méta)données sont associées à une provenance détaillée\nR1.3. Les (méta)données répondent aux normes communautaires pertinentes au domaine"
  },
  {
    "objectID": "repository.html#quels-entrepôts-de-données",
    "href": "repository.html#quels-entrepôts-de-données",
    "title": "Déposer ses données",
    "section": "2. Quels entrepôts de données ?",
    "text": "2. Quels entrepôts de données ?\nIl est important de différencier les entrepôts de données qui disposent d’un système de curation de ceux qui n’en disposent pas. La curation des données implique une gestion active et une maintenance qui peuvent inclure la vérification de la qualité, l’organisation et l’amélioration de l’accessibilité des données. Les entrepôts avec curation sont souvent plus valorisés, surtout par les revues académiques, car ils garantissent un niveau de qualité et de fiabilité plus élevé.\nPar exemple, lors de la publication d’un article de recherche, certaines revues exigent que les données sur lesquelles se base la recherche soient déposées dans des entrepôts spécifiques reconnus pour leur curation. Des revues de data paper par exemple, telles que ‘Data in Brief’ ou ‘Scientific Data’, peuvent préférer ou même exiger que les données soient hébergées dans des entrepôts certifiés, comme ceux qui sont accrédités par CoreTrustSeal, un standard qui atteste de la qualité de gestion des données.\n\nLa curation des données\n\nA la charge de l’entrepôt de données, il s’agit pour lui d’effectuer un contrôle qualité sur chaque jeu de données déposé, par un ou plusieurs “curateurs”. La curation est gratuite. La qualité des données repose sur le respect des principes FAIR (est-ce que mes données déposées respectent ces 4 principes au mieux ? Comment faire pour améliorer cela ?).\n\n\nTableau 8. Exemples d’entrepôts de données avec et sans curation\n\n\n\n\n\n\n\nEntrepôts de données sans curation\nEntrepôts de données avec curation\n\n\n\n\nZenodo\nNakala\nRe3data (Registry of Research data Repositories)\nDOAR\nICPSR (Inter-University Consortium for Political and Social Research)\nHarvard Dataverse\nDataSuds : entrepôt de l’IRD.\nRechercheDataGouv : en France.\nEntrepôt INRAE"
  },
  {
    "objectID": "repository.html#quelles-données",
    "href": "repository.html#quelles-données",
    "title": "Déposer ses données",
    "section": "3. Quelles données ?",
    "text": "3. Quelles données ?\nEn adhérant aux principes de la science ouverte, il est essentiel de privilégier l’utilisation de formats de données ouverts, libres ou pérennes. Ces formats permettent d’éviter la dépendance à un logiciel spécifique qui pourrait devenir obsolète, garantissant ainsi l’accessibilité et la réutilisabilité des données à long terme. Revoir le tableau 1 sur les formats.\nLes données déposées dans un entrepôt peuvent être sujettes à des mises à jour ou à des modifications, qui sont suivies par un système de gestion de version. Par exemple, après trois modifications d’un jeu de données, l’entrepôt indiquera que la version actuellement accessible est la version 3.\nUn entrepôt de données peut publier différents types de contenus :\n\nDes données de recherches brutes ou élaborées : Cela inclut les données originales collectées lors d’expériences ou d’études, ainsi que les données qui ont été traitées ou analysées pour en extraire ou en déduire de nouvelles informations.\nDes métadonnées : Les informations qui décrivent les données de recherche, telles que le contexte de leur collecte, la méthode utilisée pour les obtenir, et les paramètres de configuration. Ces métadonnées sont cruciales pour permettre la compréhension et la réutilisation des données de recherche par d’autres chercheurs. Publier uniquement les métadonnées peut avoir un intérêt pour sélectionner les personnes qui peuvent avoir accès au jeu de données, tout en permettant à la communauté scientifique d’être au courant de l’existence de ces données.\nCodes et logiciels : De nombreux entrepôts permettent également le dépôt de codes informatiques et de logiciels utilisés ou développés dans le cadre de la recherche, facilitant ainsi la reproduction des résultats et la transparence des analyses.\n\nCes pratiques dans les entrepôts de données non seulement renforcent la transparence scientifique mais augmentent également l’impact et la portée des recherches en permettant à d’autres chercheurs de comprendre, réutiliser et construire sur les travaux existants."
  },
  {
    "objectID": "repository.html#traiter-ses-données-limportance-du-nettoyage-de-la-restructuration",
    "href": "repository.html#traiter-ses-données-limportance-du-nettoyage-de-la-restructuration",
    "title": "Déposer ses données",
    "section": "4. Traiter ses données : l’importance du nettoyage / de la restructuration",
    "text": "4. Traiter ses données : l’importance du nettoyage / de la restructuration\nLes données ne s’utilisent jamais brutes, elles sont toujours retravaillées, restructurées. Cette restructuration peut être légère, ou peut au contraire nécessiter un important travail. Plusieurs outils existent : Python, SQL, R, OpenRefine…\nNettoyer et restructurer les données avant de les déposer dans un entrepôt de données sont des étapes cruciales pour maintenir la qualité des données à un niveau qui soutient les objectifs organisationnels et assure que l’entrepôt de données sert de source fiable. Quelques points cruciaux :\n\nFiabilité : Nettoyer les données garantit qu’elles sont exemptes d’erreurs, d’incohérences, ou de valeurs manquantes, ce qui augmente la fiabilité et la précision des analyses ultérieures.\nEfficacité : Les données propres et bien structurées permettent des analyses plus efficaces et fiables. Cela facilite l’extraction de renseignements utiles et la prise de décisions éclairées basées sur ces données.\nInteropérabilité : Des données bien structurées et normalisées facilitent l’interopérabilité avec différents systèmes et applications, permettant ainsi une plus grande flexibilité dans leur utilisation.\nConformité réglementaire : Dans de nombreux cas, nettoyer et structurer les données conformément aux normes établies est nécessaire pour répondre aux exigences réglementaires ou légales de confidentialité et de sécurité des données.\nStockage : En éliminant les redondances et en structurant correctement les données, l’espace de stockage peut être utilisé de manière plus efficace, réduisant ainsi les coûts et améliorant les performances des systèmes de gestion de données."
  },
  {
    "objectID": "repository.html#un-entrepôt-curateur-datasuds-ird",
    "href": "repository.html#un-entrepôt-curateur-datasuds-ird",
    "title": "Déposer ses données",
    "section": "5. Un entrepôt curateur : DataSuds (IRD)",
    "text": "5. Un entrepôt curateur : DataSuds (IRD)\nDataSuds est un entrepôt issu de l’application “Dataverse”. Beaucoup d’autres entrepôts sont issus de cette application comme par exemple RechercheDataGouv ou Dataverse Harvard. C’est un logiciel Open Source, gratuit, développé depuis 2006 par l’Université de Harvard.\n\nNe pas se laisser piéger par le terme “Dataverse”, il peut avoir plusieurs sens\n\nCe terme désigne plusieurs réalités qu’il faut distinguer : c’est à la fois l’application qui héberge DataSuds, mais c’est également le nom donné à des dossiers dans cette application. Un dossier peut comporter plusieurs dossiers (ou sous-dossiers). Il suffit alors de traduire “dossiers” par “dataverse” ici. Ainsi, un dataverse peut englober plusieurs dataverses, ce sont des rubriques en ce sens.\n\n\nGraphique 1. Dataverse [tdl.org]\n\nGraphique 2. Collections et Dataset [guides.dataverse.org]\n\nDataSuds recense les collections de tous les laboratoires affiliés à l’IRD ayant crée un compte. L’UMI SOURCE détient une collection. Chaque unité de recherche est responsable de sa collection. L’UMI SOURCE a donc une équipe d’administrateurs, référents, curateurs… Certains peuvent avoir plusieurs rôles, d’autres peuvent n’en avoir qu’un. Cette équipe est composée de tous les membres actifs du laboratoire volontaires : chercheurs, enseignants-chercheurs, personnels d’appui à la recherche et doctorants.\nRépartition des rôles DataSuds\n\nL’équipe référente est en charge à la fois d’accompagner, de réviser, de valider les jeux de données soumis dans la collection de DataSuds.\n\n5.1. Connexion et création d’un compte utilisation\nEtape 1\n\nEtape 2\n\nEtape 3\n\n\n\n5.2. Créer un jeu de données\nEtape 4\n\nEtape 5\n\nEtape 6\n\nEtape 7\n\n\n\n5.3. Version provisoire du jeu de données à compléter et valider\nEtape 8\n\nÉtape 9\n\n\n\n5.4. La forme finale du dépôt\nÉtape 10\n\nÉtape 11\n\nÉtape 12\n\nÉtape 13"
  },
  {
    "objectID": "repository.html#références",
    "href": "repository.html#références",
    "title": "Déposer ses données",
    "section": "6. Références",
    "text": "6. Références\n\n6.1. Personnes ressources à l’UMI SOURCE\nLoïc Pian : loic.pian@uvsq.fr\nAlexandre Mathieu : alexmathieu.ln@gmail.com / alexandre.mathieu@universite-paris-saclay.fr\nDominique Couret : dominique.couret@ird.fr\nLa constitution d’une équipe structurée, regroupant les membres des quatre antennes, est en cours.\nLes administrateurs de l’entrepôt DataSuds : data.ird.fr\n\n\n6.2. Autres ressources\n\nEntrepôt DataSuds : https://datasuds.ird.fr/\nTutoriels de l’INRA :\n\nCréation Dataset : https://youtu.be/glN8TVxTRK4\nCréation Dataverse : https://youtu.be/mYPzZ04JWbY\n\n\nC’est un autre entrepôt, mais du même mode que DataSuds puisque sur la même application qu’est Dataverse.\n\nManuel de Dataverse : http://guides.dataverse.org/en/4.20/user/index.html\nFormations de l’IRD :\n\nLuc Decker, “DataSuds : Entrepôt de données scientifiques de l’IRD” (2024)\nLuc Decker, Hanka Hensens, Caroline Doucouré, “Déposer des données dans l’entrepôt DataSuds” (2023)"
  }
]